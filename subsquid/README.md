# Subsquid

## Prerequisites

* [Node 16.x](https://nodejs.org/)
* [Docker](https://docs.docker.com/get-docker/)
* [GNU Make](https://www.gnu.org/software/make/)

## Quickly running

```bash
# 1. Install dependencies
npm ci

# 2. Build Docker images and run 
# This can be used to restart and reprocess too
make restart
```

The GraphQL playground is available at http://localhost:4350/graphql. Open it in a browser and run sample queries by applying filters and data selections in the panel to the left.

## Dev flow

### 1. Define database schema

Start development by defining the schema of the target database via `schema.graphql`.
Schema definition consists of regular graphql type declarations annotated with custom directives.
Full description of `schema.graphql` dialect is available [here](https://docs.subsquid.io/develop-a-squid/schema-file/).

#### Entity Requirements

Entities *must* include the following fields:
- id: Natural key (for example, `ctx.event.id` for `Event` or `accountId` for `Account`) or random UUID. 
- eventId: ID of the event that triggered the creation/update (can be obtained from `ctx.event.id`)

Optionally, they can also include any other id that can be associated with the on-chain entity. When possible, this must come directly from the chain events (like `offerId` for bond offers). Otherwise, it can be created as a unique concatenation of available data separated by a dash (`-`), like `${accountId}-${assetId}` for vesting schedules.

### 2. Generate TypeORM classes

Mapping developers use TypeORM [EntityManager](https://typeorm.io/#/working-with-entity-manager)
to interact with target database during data processing. All necessary entity classes are
generated by the squid framework from `schema.graphql`. This is done by running:

```bash
make codegen 
```

In most cases the simplest way to update the schema is to drop the database and regenerate the migrations from scratch.

1. Update `schema.graphql`
2. Regenerate the model classes and build the squid with `make rebuild`


### 3. Generate TypeScript definitions for substrate events and calls

This is an optional part, but it is very advisable. 

Event, call and runtime storage data comes to mapping handlers as a raw untyped json. 
While it is possible to work with raw untyped json data, it's extremely error-prone and moreover the json structure may change over time due to runtime upgrades.

Squid framework provides tools for generation of type-safe, spec version aware wrappers around events, calls and runtime storage items. Typegen generates type-safe classes in `types/events.ts`, `types/calls.ts` and `types/storage.ts` respectively, with constructors taking `XXXContext` interfaces as the only argument. All historical runtime upgrades are accounted out of the box. A typical usage is as follows (see `src/processor.ts`):

```typescript
function getTransferEvent(ctx: EventHandlerContext): TransferEvent {
  // instantiate the autogenerated type-safe class for Balances.Transfer event
  const event = new BalancesTransferEvent(ctx);
  // for each runtime version, reduce the data to the common interface
  if (event.isV1020) {
    const [from, to, amount] = event.asV1020;
    return { from, to, amount };
  } else if (event.isV1050) {
    const [from, to, amount] = event.asV1050;
    return { from, to, amount };
  } else {
    const { from, to, amount } = event.asV9130;
    return { from, to, amount };
  }
}
``` 

Generation of type-safe wrappers for events, calls and storage items is currently a two-step process.

First, you need to spin a temporary unsafe node, by going to https://github.com/ComposableFi/SRE/actions/workflows/temporary-node.yml, clicking on
`Run workflow` and providing the default parameters:
```text
Branch: main
Environment: picasso,
Version: <leave blank>
```

This will take a couple of minutes, until the `Ready to go` stage is done. This will provide the node details as in the following example:
```bash
Node ghr-3efa9c running 4.10012.0 should now be caught up and available at ws://35.228.177.108:9944
```

This `ws` endpoint (`ws://35.228.177.108:9944` in our example) will be used in the next step.

Now you need to explore the chain to get the metadata and output the specs file. Remember to replace the `ws` endpoint with the one obtained above.

```bash
npx squid-substrate-metadata-explorer \
  --chain ws://35.228.177.108:9944 \
  --out picassoVersions.jsonl
```

After chain exploration is complete you can generate required wrappers:


```bash
make typegen
```

The configuration for this can be viewed and change on `typegen.json`, which has the following structure:

```json5
{
  "outDir": "src/types",
  "specVersions": "picassoVersions.jsonl",
  "typesBundle": "kusama",
  "events": [
    // List of events to generate
    "Balances.Transfer",
    "Pablo.PoolCreated",
  ],
  "calls": [
    // list of calls to generate
    "timestamp.set"
  ],
  "storage": [
    // list of storage items.
    "System.Account"
  ]
}
```

### 4. Modify GraphQL resolvers

Custom resolvers can be found at `/src/server-extension/resolvers`. In order to add a new resolver, you need to create 
a new typescript file inside this folder, like `myCustomResolver.ts`. There are many examples to copy inside that folder.

Then you need to import it inside `/src/server-extension/resolvers/index.ts`,
like this:

```typescript
import { MyCustomResolver } from "./myCustomResolver";
```

and add it to the export list on the same file.

```typescript
export {
  /// ...
  MyCustomResolver,
}
```

Finally, you need to restart the GraphQL server. If the processors have not been modified, you can simply rebuild the docker image and restart the processes, by running:

```bash
make rebuild-graphql
```

Otherwise, you need to restart the whole stack, and wait for the processor to go through all the events again, by running:

```bash
make restart
```

### 5. Logs

#### Local
If you want to see the logs of the containers running locally, you can check the names of the containers running with:

```bash
docker ps --format "{{.Names}}"
```

This should print something like:
```bash
subsquid_explorer_1
subsquid_graphql-server_1
subsquid_processor_1
subsquid_squid-db_1
subsquid_db_1
```

In order to view the logs of the processor, you can run:

```bash
docker logs subsquid_processor_1 -f
```

This should show you the progress of the processing, as in:
```bash
{"level":2,"time":1680539954584,"ns":"sqd:processor","msg":"2120357 / 2120357, rate: 0 blocks/sec, mapping: 72 blocks/sec, 0 items/sec, ingest: 1 blocks/sec, eta: 0s"}
```

Similarly, you can view the logs of the other containers.

#### Remote

Our remote servers are running on Google Cloud Platform. In order to access the logs, you need to ask for permissions and instructions from the SRE team.

## Deploy

In order to deploy Subsquid you need to visit https://github.com/ComposableFi/SRE/actions/workflows/deploy_subsquid.yml
and click on `Run workflow`. You will need to provide the following parameters.

#### Staging
```text
Branch: main
Host: ~composable-ci-subsquid-01~composable-ci~
Image tag: <image tag of release> (read below*)
Trigger reprocessing: true (read below**),
Stats: https://stats-stage.composablenodes.tech/graphql
```

#### Production
```text
Branch: main
Host: ~picass-network-subsquid-01~picasso-network~
Image tag: <image tag of release> (read below*)
Trigger reprocessing: true (read below**),
Stats: https://statas.composablenodes.tech/graphql
```

##### *Image tag
This can be obtained from https://hub.docker.com/r/composablefi/subsquid-processor/tags. You should use the specific tag instead of `latest`.

##### **Trigger reprocessing
This will normally be set to true, and will force Subsquid to reprocess the whole history.
Can be set to `false` when the only changes were made on the `Graphql` resolvers, and not the processors.
Otherwise, data already processed might be incorrect, and if the schema changed the process will break
as soon as it tries to process a block with the old schema.